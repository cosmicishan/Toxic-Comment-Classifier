{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_Comment_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Depenedncies"
      ],
      "metadata": {
        "id": "HMqR-s8dEarG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N-nDHhuyjxPV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data"
      ],
      "metadata": {
        "id": "5wiH6-plEx-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/Toxic-Comment/train.csv')"
      ],
      "metadata": {
        "id": "SvkyPVvLEzrI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rHTpKpgD9BMu",
        "outputId": "042fb851-4930-4b88-8366-da431973a93a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad050d42-8c7c-481d-9d3e-76976d8f5afb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad050d42-8c7c-481d-9d3e-76976d8f5afb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad050d42-8c7c-481d-9d3e-76976d8f5afb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad050d42-8c7c-481d-9d3e-76976d8f5afb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "ZTmv6YeYErIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dependent and Independent variable."
      ],
      "metadata": {
        "id": "aSacghgEFAQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values"
      ],
      "metadata": {
        "id": "9x2W037lEsqv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization"
      ],
      "metadata": {
        "id": "XNZSuSmlFJou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Turning sentences into numerical representation to feed it into neural network."
      ],
      "metadata": {
        "id": "sk3wTteeFMQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_FEATURES = 200000 # number of words in the vocab"
      ],
      "metadata": {
        "id": "1PE1BNtPFFI5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800, #Capping the sentence into 1800 words.\n",
        "                               output_mode='int')"
      ],
      "metadata": {
        "id": "94M_ppV2FHeL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizer model learning from the data."
      ],
      "metadata": {
        "id": "4n3p6_uZFyLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.adapt(X.values)"
      ],
      "metadata": {
        "id": "xDXYV_XqFl7G"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer('Hello, World!')[:3:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bDLsQZYF73j",
        "outputId": "201ca99a-51df-4720-d8c0-0ecf0bb4adc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([288, 263,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking one random sentence for example to see how the vectorizer model works. The word 'Hello' is represented with the number 288 while the 'World' is reprsented with the number 263. The vector contains 1800 columns means the max length of sentence is 1800. "
      ],
      "metadata": {
        "id": "BR-fsTZAGDqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataset with all the training dataset comment vectorized.\n"
      ],
      "metadata": {
        "id": "7EbQEMQJF2HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text = vectorizer(X.values)"
      ],
      "metadata": {
        "id": "CyJrlfldFn2k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeing how the vectorized training data looks."
      ],
      "metadata": {
        "id": "YvvKSVp3GeEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JI2A13qGYzg",
        "outputId": "f39b8ffc-34f0-4784-a667-1a8771dcb697"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
              "array([[  645,    76,     2, ...,     0,     0,     0],\n",
              "       [    1,    54,  2489, ...,     0,     0,     0],\n",
              "       [  425,   441,    70, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [32445,  7392,   383, ...,     0,     0,     0],\n",
              "       [    5,    12,   534, ...,     0,     0,     0],\n",
              "       [    5,     8,   130, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the particular sentence doesn't meet the max length of 1800, it will pad out the columns with zeroes.\n"
      ],
      "metadata": {
        "id": "hzpIXv0pG2y8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create dataset by slicing the data into baches and shuffling it."
      ],
      "metadata": {
        "id": "9FVK7VzfT0Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks"
      ],
      "metadata": {
        "id": "wc-shPH7TuTZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, validation, Test split."
      ],
      "metadata": {
        "id": "1g2k0S-GT4TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ],
      "metadata": {
        "id": "vMnQUTTPTvvi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using 70% of the data as training set, 20% of the data as validation set and 10% as testing set."
      ],
      "metadata": {
        "id": "W6yAgGlaUYga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "1IHbunR2T7ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Sequential model"
      ],
      "metadata": {
        "id": "SF6LGRbmUh97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# Create the embedding layer \n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "# Bidirectional LSTM Layer\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "# Feature extractor Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Final layer model.compile(loss='BinaryCrossentropy', optimizer='Adam')\n",
        "model.add(Dense(6, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "c01NoNSET9O2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Bi-directional LSTM. So the data can be feed to the network from both side. \n",
        "\n",
        "Adavantage: \n",
        "\n",
        "Example : \"I don't hate you.\"\n",
        "\n",
        "The network could see the word hate and think of it as the hate comment but by feeding the data with both direction it could catch the word 'Don't'"
      ],
      "metadata": {
        "id": "bYKDRO96UnKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ],
      "metadata": {
        "id": "yvS33fIyUqQ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vb3mt7tVAbi",
        "outputId": "48ef64ce-2eb6-496d-bac2-47d2c7584e70"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,491,686\n",
            "Trainable params: 6,491,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train, epochs=1, validation_data=val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aekGvgNmVD7e",
        "outputId": "cdb6618b-142f-4094-9c08-ee475ffcab4e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6981/6981 [==============================] - 665s 94ms/step - loss: 0.0625 - val_loss: 0.0480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing on our text by getting the percentage of the toxicity from different classes.\n"
      ],
      "metadata": {
        "id": "v9PHgHP38tNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = vectorizer(\"Hey, bitch. You freaking suck!\")\n",
        "\n",
        "input_text = tf.convert_to_tensor(np.array([text]))\n",
        "\n",
        "res = model.predict(input_text)[0]\n",
        "\n",
        "for i, j in zip(df.columns[2:], res):\n",
        "\n",
        "  print(i + ': ' + str(j))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOueANYN3ssk",
        "outputId": "2d6e89b2-f10a-4d00-f085-7457019bd474"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic: 0.99936336\n",
            "severe_toxic: 0.43180236\n",
            "obscene: 0.98312193\n",
            "threat: 0.047626756\n",
            "insult: 0.910321\n",
            "identity_hate: 0.29512954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the model"
      ],
      "metadata": {
        "id": "unzCMs-t9ucy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "Txj4Wq839waR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test.as_numpy_iterator(): \n",
        "  \n",
        "    # Unpack the batch \n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction \n",
        "    yhat = model.predict(X_true)\n",
        "    \n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "    \n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)"
      ],
      "metadata": {
        "id": "ojKtwWHN952e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3KDkvSu9_1x",
        "outputId": "3d788bb0-0fe5-4b44-c704-e03930779937"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8320522904396057, Recall:0.6178653240203857, Accuracy:0.48445335030555725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deplying the model from gradio app"
      ],
      "metadata": {
        "id": "wOkAo4Y1aqEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio is the fastest way to demo your machine learning model with a friendly web interface so that anyone can use it, anywhere for temporary amount of time."
      ],
      "metadata": {
        "id": "6YO_li4Ma6lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "5NOWoCeha1r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment):\n",
        "    vectorized_comment = vectorizer([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "    \n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, round(results[0][idx]*100, 2))\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "u1ECDUIpa_4G"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of how the text would look in web interface."
      ],
      "metadata": {
        "id": "sHla45a4e28G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(score_comment('I hate you so much!'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwjJ8Y5PecAA",
        "outputId": "913ad568-139a-4732-fcaa-34ecee167536"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic: 60.45\n",
            "severe_toxic: 1.17\n",
            "obscene: 21.9\n",
            "threat: 2.32\n",
            "insult: 32.41\n",
            "identity_hate: 5.38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(fn=score_comment, \n",
        "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Comment to classify classes of toxicity.'),\n",
        "                        outputs='text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8yG_nefbeqC",
        "outputId": "1a176c26-597a-42cc-aa94-3f15484534cd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is how we will get the result in the web interface.\n",
        "The box in write take input comment and we will get the output in the right box with the percentage of the toxicity from a different class."
      ],
      "metadata": {
        "id": "BuzwmUk6hUiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "syRrLgePbhVb",
        "outputId": "d73308f2-30d6-4be3-ba45-2804e21d260d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://58509.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://58509.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7faf598b6e10>,\n",
              " 'http://127.0.0.1:7862/',\n",
              " 'https://58509.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}